{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2: EDA \n",
    "--- \n",
    "\n",
    "## Loading in necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading, Cleaning, and Almagimating My Dataset:\n",
    "\n",
    "I wanted to group the different cities that are in a similar climate zone. I decided the most sensical way to sort the data was to have these different columns heads: \n",
    "\n",
    "- British Columbia \n",
    "- The Prairie Provinces\n",
    "- Ontario \n",
    "- Quebec \n",
    "- The Atlantic Provinces \n",
    "- The Northern Provinces\n",
    "\n",
    "I used method chaining to form these functions and then added them to the scripts file located in my groups analysis repository so everyone could do the same thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process(url_or_path_to_csv_file):\n",
    "    # Method Chain 1 (Load data, deal with missing data, and making data readable)\n",
    "    df1 = (\n",
    "        pd.read_csv(url_or_path_to_csv_file)\n",
    "        .rename(columns ={\"LOCAL_DATE\":\"DATE\"})\n",
    "        .assign(DATE = pd.to_datetime(df['DATE'], yearfirst = True).dt.date)\n",
    "        .sort_values(\"DATE\", ascending=False)\n",
    "        .dropna()\n",
    "        .reset_index(drop = True)\n",
    "         )\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a3a2dd3fd0c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Canadian_climate_history (1970-2020).csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-7461632a5bce>\u001b[0m in \u001b[0;36mload_and_process\u001b[0;34m(url_or_path_to_csv_file)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_path_to_csv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"LOCAL_DATE\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"DATE\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myearfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DATE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = load_and_process('Canadian_climate_history (1970-2020).csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method Chain 2 (Creating new columns for different regions of Canada)\n",
    "def group_columns(df):\n",
    "    df2 = (\n",
    "        #create new columns that take mean temperature and percipitation from Atlantic Provinces \n",
    "        df\n",
    "        .assign(TEMPERATURE_ATLANTIC = (df.iloc[:, [5, 7, 17]].mean(axis=1)).round(decimals=1))\n",
    "        .assign(PERCIPITATION_ATLANTIC = (df.iloc[:, [6, 8, 18]].mean(axis=1)).round(decimals=1))\n",
    "        \n",
    "        #create new columns that take mean temperature and percipitation from Prairie provinces \n",
    "        .assign(TEMPERATURE_PRAIRIES = (df.iloc[:, [1, 3, 15, 25]].mean(axis=1)).round(decimals=1))\n",
    "        .assign(PERCIPITATION_PRAIRIES = (df.iloc[:, [2, 4, 16, 26]].mean(axis=1)).round(decimals=1))\n",
    "        \n",
    "        #create new columns that take mean temperature and percipitation from cities in Ontario and merge into single column\n",
    "        .assign(TEMPERATURE_ONTARIO = (df.iloc[:, [11, 19]].mean(axis=1)).round(decimals=1))\n",
    "        .assign(PERCIPITATION_ONTARIO = (df.iloc[:, [12, 20]].mean(axis=1)).round(decimals=1))\n",
    "        \n",
    "         #create new columns that take mean temperature and percipitation from cities in Quebec and merge into single column\n",
    "        .assign(TEMPERATURE_QUEBEC = (df.iloc[:, [9, 13]].mean(axis=1)).round(decimals=1))\n",
    "        .assign(PERCIPITATION_QUEBEC = (df.iloc[:, [10, 14]].mean(axis=1)).round(decimals=1))\n",
    "        \n",
    "        #dropping columns that were amalgimated into the means\n",
    "        .drop(columns = ['MEAN_TEMPERATURE_CALGARY', 'TOTAL_PRECIPITATION_CALGARY', 'MEAN_TEMPERATURE_EDMONTON', 'TOTAL_PRECIPITATION_EDMONTON', \n",
    "                         'MEAN_TEMPERATURE_HALIFAX', 'TOTAL_PRECIPITATION_HALIFAX', 'MEAN_TEMPERATURE_MONCTON', 'TOTAL_PRECIPITATION_MONCTON',\n",
    "                        'MEAN_TEMPERATURE_SASKATOON', 'TOTAL_PRECIPITATION_SASKATOON', 'MEAN_TEMPERATURE_STJOHNS', 'TOTAL_PRECIPITATION_STJOHNS',\n",
    "                        'MEAN_TEMPERATURE_WINNIPEG', 'TOTAL_PRECIPITATION_WINNIPEG', 'MEAN_TEMPERATURE_OTTAWA', 'TOTAL_PRECIPITATION_OTTAWA',\n",
    "                        'MEAN_TEMPERATURE_TORONTO', 'TOTAL_PRECIPITATION_TORONTO', 'MEAN_TEMPERATURE_MONTREAL', 'TOTAL_PRECIPITATION_MONTREAL',\n",
    "                        'MEAN_TEMPERATURE_QUEBEC', 'TOTAL_PRECIPITATION_QUEBEC'])\n",
    "        \n",
    "        #renaming columns to meet new location based naming\n",
    "        .rename(columns ={\"MEAN_TEMPERATURE_VANCOUVER\":\"TEMPERATURE_BRITISH_COLUMBIA\"})\n",
    "        .rename(columns ={\"TOTAL_PRECIPITATION_VANCOUVER\":\"PRECIPITATION_BRITISH_COLUMBIA\"})\n",
    "        .rename(columns ={\"MEAN_TEMPERATURE_WHITEHORSE\":\"TEMPERATURE_NORTHERN\"})\n",
    "        .rename(columns ={\"TOTAL_PRECIPITATION_WHITEHORSE\":\"PRECIPITATION_NORTHERN\"})\n",
    "    )\n",
    "        \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = group_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pandas_profiling \n",
    "---\n",
    "I wanted to use pandas profiling to get a basic idea of different correlation and information about my dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling as pdp\n",
    "dfprofile = pdp.ProfileReport(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfprofile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sns.pair plot \n",
    "---\n",
    "I ran this function not known how long it would take. However, it shows a lot of good graphs and I think it is a good starting point of my exploration. I can see some definite correlations. I put the # symbol there so it doesn't automatically run because it takes too long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations \n",
    "---\n",
    "## Looking at the data types \n",
    "When I was first trying to make graphs it was difficult because I wasn't aware that the date object must be on the x-axis in the plot. I used .dtype to make sure I could plot everything in my dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making some displots \n",
    "\n",
    "In an attempt to visualize I wanted to make some displots to see there was an upward trend in temperatures across Canada throughout time. \n",
    "\n",
    "#### British Columbia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df2,\n",
    "           y = \"TEMPERATURE_BRITISH_COLUMBIA\",\n",
    "           x = \"DATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Northern Provinces: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df2,\n",
    "           y = \"TEMPERATURE_NORTHERN\",\n",
    "           x = \"DATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prairie Provinces: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df2,\n",
    "           y = \"TEMPERATURE_PRAIRIES\",\n",
    "           x = \"DATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ontario: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df2,\n",
    "           y = \"TEMPERATURE_ONTARIO\",\n",
    "           x = \"DATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quebec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df2,\n",
    "           y = \"TEMPERATURE_QUEBEC\",\n",
    "           x = \"DATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Atlantic Provinces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df2,\n",
    "           y = \"TEMPERATURE_ATLANTIC\",\n",
    "           x = \"DATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My notes: \n",
    "\n",
    "After making these it is clear that when initially cleaning the data and dropping null value it got rid of a lot of the data points prior to 1985. The graphs I made are pretty busy and I'm not sure if they are the best way to visualize the data. \n",
    "\n",
    "As the graphs are now there is a lot of weight in the mid-range temperature throughout most the graph. This makes sense as the current graphs are based on how many time a certain temperature is recorded throughout the year. I think a better approach might be to subdivide the dataset by the different months and monitor if certain months have been changing overtime. I think this might be better as it will more clearly show change and there will not be so many data points on the plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdividing the dataframe: \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
